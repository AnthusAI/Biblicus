{
  "benchmark_timestamp": "2026-02-03T20:54:39.694874",
  "corpus_path": "corpora/funsd_benchmark",
  "total_pipelines": 8,
  "successful_pipelines": 8,
  "failed_pipelines": 0,
  "pipelines": [
    {
      "name": "baseline-ocr",
      "snapshot_id": "b5ee5f5d3441fe89cbcc266579578923212b467c035cae2c652bb0bd66a8b954",
      "success": true,
      "metrics": {
        "set_based": {
          "avg_f1": 0.6072843202661438,
          "avg_precision": 0.6255081563853031,
          "avg_recall": 0.5992724615693936,
          "median_f1": 0.6551724137931034
        },
        "order_aware": {
          "avg_word_error_rate": 0.627676995981824,
          "avg_sequence_accuracy": 0.01264967367994974,
          "avg_lcs_ratio": 0.46531647331379516,
          "median_word_error_rate": 0.7117117117117117,
          "median_sequence_accuracy": 0.009009009009009009
        },
        "ngram": {
          "avg_bigram_overlap": 0.34975804965879437,
          "avg_trigram_overlap": 0.25338933579797057
        }
      },
      "pipeline_configuration": {
        "extractor_id": "pipeline",
        "config": {
          "steps": [
            {
              "extractor_id": "ocr-tesseract",
              "config": {
                "min_confidence": 0.0,
                "lang": "eng",
                "psm": 3,
                "oem": 3
              }
            }
          ]
        }
      },
      "total_documents": 20,
      "processing_time": 0.07872200012207031
    },
    {
      "name": "ocr-rapidocr",
      "snapshot_id": "2f63e7792fae7f57bc586c64e5417e06e3198f6a9b9472446300a95b6593c92b",
      "success": true,
      "metrics": {
        "set_based": {
          "avg_f1": 0.5074752083465316,
          "avg_precision": 0.5684821454871473,
          "avg_recall": 0.46722698561676745,
          "median_f1": 0.5132743362831858
        },
        "order_aware": {
          "avg_word_error_rate": 0.7484695207726699,
          "avg_sequence_accuracy": 0.013590403245607136,
          "avg_lcs_ratio": 0.33356368139734216,
          "median_word_error_rate": 0.7619047619047619,
          "median_sequence_accuracy": 0.0045045045045045045
        },
        "ngram": {
          "avg_bigram_overlap": 0.20618346365657697,
          "avg_trigram_overlap": 0.12269005962940223
        }
      },
      "pipeline_configuration": {
        "extractor_id": "pipeline",
        "config": {
          "steps": [
            {
              "extractor_id": "ocr-rapidocr",
              "config": {
                "min_confidence": 0.0
              }
            }
          ]
        }
      },
      "total_documents": 20,
      "processing_time": 0.061985015869140625
    },
    {
      "name": "ocr-paddleocr",
      "snapshot_id": "81a579d14d87cf78e4ec0942ba99517961a072d92074770b5eb09208b653b286",
      "success": true,
      "metrics": {
        "set_based": {
          "avg_f1": 0.7871177688651299,
          "avg_precision": 0.799119079118136,
          "avg_recall": 0.7820890302073592,
          "median_f1": 0.8050847457627118
        },
        "order_aware": {
          "avg_word_error_rate": 0.5327441288659603,
          "avg_sequence_accuracy": 0.031226865900204282,
          "avg_lcs_ratio": 0.6069223336452031,
          "median_word_error_rate": 0.5533333333333333,
          "median_sequence_accuracy": 0.019230769230769232
        },
        "ngram": {
          "avg_bigram_overlap": 0.46569813969184864,
          "avg_trigram_overlap": 0.3525906731900442
        }
      },
      "pipeline_configuration": {
        "extractor_id": "pipeline",
        "config": {
          "steps": [
            {
              "extractor_id": "ocr-paddleocr-vl",
              "config": {
                "min_confidence": 0.0,
                "lang": "en"
              }
            }
          ]
        }
      },
      "total_documents": 20,
      "processing_time": 0.07769584655761719
    },
    {
      "name": "docling-smol",
      "snapshot_id": "298d4b5b8dec6f4a829c0e8c0cc640c54b01f81bd10f329cc1fd97cf291a4367",
      "success": true,
      "metrics": {
        "set_based": {
          "avg_f1": 0.727858478565952,
          "avg_precision": 0.8212242069943816,
          "avg_recall": 0.6746073701642105,
          "median_f1": 0.8023255813953488
        },
        "order_aware": {
          "avg_word_error_rate": 0.6447251465477195,
          "avg_sequence_accuracy": 0.020934301250577218,
          "avg_lcs_ratio": 0.5140081696779368,
          "median_word_error_rate": 0.7105263157894737,
          "median_sequence_accuracy": 0.013157894736842105
        },
        "ngram": {
          "avg_bigram_overlap": 0.4297822031812827,
          "avg_trigram_overlap": 0.3331556378629154
        }
      },
      "pipeline_configuration": {
        "extractor_id": "pipeline",
        "config": {
          "steps": [
            {
              "extractor_id": "docling-smol",
              "config": {}
            }
          ]
        }
      },
      "total_documents": 20,
      "processing_time": 0.06859421730041504
    },
    {
      "name": "unstructured",
      "snapshot_id": "34886725d3627fbc97b82907c04f0be383c42cbac3ff38ae717d55e912c3c585",
      "success": true,
      "metrics": {
        "set_based": {
          "avg_f1": 0.6486202977131753,
          "avg_precision": 0.6835320660081694,
          "avg_recall": 0.6264811364481051,
          "median_f1": 0.7164179104477612
        },
        "order_aware": {
          "avg_word_error_rate": 0.5977040158314746,
          "avg_sequence_accuracy": 0.014024395385147187,
          "avg_lcs_ratio": 0.49993154733999184,
          "median_word_error_rate": 0.5789473684210527,
          "median_sequence_accuracy": 0.005780346820809248
        },
        "ngram": {
          "avg_bigram_overlap": 0.3828328534963109,
          "avg_trigram_overlap": 0.28771943983702924
        }
      },
      "pipeline_configuration": {
        "extractor_id": "pipeline",
        "config": {
          "steps": [
            {
              "extractor_id": "unstructured",
              "config": {}
            }
          ]
        }
      },
      "total_documents": 20,
      "processing_time": 0.0746469497680664
    },
    {
      "name": "layout-aware-ocr",
      "snapshot_id": "62cb365943943e8da0523d8944bf85f1535117351854fc18780021939bc90595",
      "success": true,
      "metrics": {
        "set_based": {
          "avg_f1": 0.5653363795739467,
          "avg_precision": 0.5984695591109972,
          "avg_recall": 0.5443472690948843,
          "median_f1": 0.5728643216080401
        },
        "order_aware": {
          "avg_word_error_rate": 0.8050865097371342,
          "avg_sequence_accuracy": 0.009442267413676993,
          "avg_lcs_ratio": 0.34066591780716327,
          "median_word_error_rate": 0.8028169014084507,
          "median_sequence_accuracy": 0.009009009009009009
        },
        "ngram": {
          "avg_bigram_overlap": 0.2729359536131234,
          "avg_trigram_overlap": 0.16337833130050625
        }
      },
      "pipeline_configuration": {
        "extractor_id": "pipeline",
        "config": {
          "steps": [
            {
              "extractor_id": "mock-layout-detector",
              "config": {
                "layout_type": "two-column"
              }
            },
            {
              "extractor_id": "ocr-tesseract",
              "config": {
                "use_layout_metadata": true,
                "min_confidence": 0.0,
                "lang": "eng",
                "psm": 3,
                "oem": 3
              }
            }
          ]
        }
      },
      "total_documents": 20,
      "processing_time": 0.08019399642944336
    },
    {
      "name": "layout-aware-rapidocr",
      "snapshot_id": "c54a4624b8f43290bfc72aa238b85baac0337c14ebc108f3888ea3b5a6771c19",
      "success": true,
      "metrics": {
        "set_based": {
          "avg_f1": 0.5074752083465316,
          "avg_precision": 0.5684821454871473,
          "avg_recall": 0.46722698561676745,
          "median_f1": 0.5132743362831858
        },
        "order_aware": {
          "avg_word_error_rate": 0.7484695207726699,
          "avg_sequence_accuracy": 0.013590403245607136,
          "avg_lcs_ratio": 0.33356368139734216,
          "median_word_error_rate": 0.7619047619047619,
          "median_sequence_accuracy": 0.0045045045045045045
        },
        "ngram": {
          "avg_bigram_overlap": 0.20618346365657697,
          "avg_trigram_overlap": 0.12269005962940223
        }
      },
      "pipeline_configuration": {
        "extractor_id": "pipeline",
        "config": {
          "steps": [
            {
              "extractor_id": "mock-layout-detector",
              "config": {
                "layout_type": "two-column"
              }
            },
            {
              "extractor_id": "ocr-rapidocr",
              "config": {
                "min_confidence": 0.0
              }
            }
          ]
        }
      },
      "total_documents": 20,
      "processing_time": 0.06006288528442383
    },
    {
      "name": "layout-aware-paddleocr",
      "snapshot_id": "4410d712ed9bfb73a2480cb34b1f2d153d36acaa373764790824a122ece7ba62",
      "success": true,
      "metrics": {
        "set_based": {
          "avg_f1": 0.0,
          "avg_precision": 0.0,
          "avg_recall": 0.0,
          "median_f1": 0.0
        },
        "order_aware": {
          "avg_word_error_rate": 1.0,
          "avg_sequence_accuracy": 0.0,
          "avg_lcs_ratio": 0.0,
          "median_word_error_rate": 1.0,
          "median_sequence_accuracy": 0.0
        },
        "ngram": {
          "avg_bigram_overlap": 0.0,
          "avg_trigram_overlap": 0.0
        }
      },
      "pipeline_configuration": {
        "extractor_id": "pipeline",
        "config": {
          "steps": [
            {
              "extractor_id": "mock-layout-detector",
              "config": {
                "layout_type": "two-column"
              }
            },
            {
              "extractor_id": "ocr-paddleocr-vl",
              "config": {
                "min_confidence": 0.0,
                "lang": "en"
              }
            }
          ]
        }
      },
      "total_documents": 20,
      "processing_time": 0.010917901992797852
    }
  ],
  "best_performers": {
    "best_f1": "ocr-paddleocr",
    "best_sequence_accuracy": "ocr-paddleocr",
    "lowest_wer": "ocr-paddleocr",
    "best_bigram": "ocr-paddleocr"
  }
}