# Biblicus STT Benchmark - Quick Configuration
#
# Quick STT benchmark for development iteration.
# Runs ~20 audio files for fast feedback.
# Expected runtime: ~2-5 minutes (depending on API latency)

benchmark_name: stt-quick

categories:
  librispeech:
    dataset: librispeech-test-clean
    corpus_path: corpora/librispeech_benchmark
    ground_truth_subdir: ground_truth
    primary_metric: wer
    subset_size: 20
    tags:
      - librispeech
      - test-clean
      - speech
      - ground-truth

# STT providers to benchmark
providers:
  - name: OpenAI Whisper
    extractor_id: stt-openai
    config:
      model: whisper-1
      response_format: json

  - name: Deepgram Nova-3
    extractor_id: stt-deepgram
    config:
      model: nova-3
      punctuate: true
      smart_format: true

  - name: Aldea
    extractor_id: stt-aldea
    config: {}

output_dir: results/stt_benchmark
