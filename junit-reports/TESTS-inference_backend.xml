<testsuite name="inference_backend.Inference backend configuration" tests="9" errors="0" failures="0" skipped="0" time="0.078848" timestamp="2026-01-29T13:53:16.567029" hostname="JW2TF3YWMJ"><testcase classname="inference_backend.Inference backend configuration" name="API mode requires api_provider to be set" status="passed" time="0.011468"><system-out>
<![CDATA[
@scenario.begin
  Scenario: API mode requires api_provider to be set
    Given I initialized a corpus at "corpus" ... passed in 0.003s
    And a file "image.png" exists with bytes: ... passed in 0.000s
      """
      \x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\x00\x01\x00\x00\x00\x01\x08\x02\x00\x00\x00\x90wS\xde\x00\x00\x00\x0bIDATx\x9cc\x00\x01\x00\x00\x05\x00\x01\r\n-\xb4\x00\x00\x00\x00IEND\xaeB`\x82
      """
    When I ingest the file "image.png" into corpus "corpus" ... passed in 0.004s
    And I attempt to build a "ocr-paddleocr-vl" extraction run in corpus "corpus" using the recipe: ... passed in 0.004s
      """
      extractor_id: ocr-paddleocr-vl
      config:
        backend:
          mode: api
      """
    Then the command fails with exit code 2 ... passed in 0.000s

@scenario.end
--------------------------------------------------------------------------------
]]>
</system-out></testcase><testcase classname="inference_backend.Inference backend configuration" name="API mode with HuggingFace provider requires API key" status="passed" time="0.010931"><system-out>
<![CDATA[
@scenario.begin
  Scenario: API mode with HuggingFace provider requires API key
    Given I initialized a corpus at "corpus" ... passed in 0.003s
    And a file "image.png" exists with bytes: ... passed in 0.000s
      """
      \x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\x00\x01\x00\x00\x00\x01\x08\x02\x00\x00\x00\x90wS\xde\x00\x00\x00\x0bIDATx\x9cc\x00\x01\x00\x00\x05\x00\x01\r\n-\xb4\x00\x00\x00\x00IEND\xaeB`\x82
      """
    When I ingest the file "image.png" into corpus "corpus" ... passed in 0.004s
    And I attempt to build a "ocr-paddleocr-vl" extraction run in corpus "corpus" using the recipe: ... passed in 0.004s
      """
      extractor_id: ocr-paddleocr-vl
      config:
        backend:
          mode: api
          api_provider: huggingface
      """
    Then the command fails with exit code 2 ... passed in 0.000s

@scenario.end
--------------------------------------------------------------------------------
]]>
</system-out></testcase><testcase classname="inference_backend.Inference backend configuration" name="API mode reads HuggingFace API key from environment" status="passed" time="0.012639"><system-out>
<![CDATA[
@scenario.begin
  Scenario: API mode reads HuggingFace API key from environment
    Given I initialized a corpus at "corpus" ... passed in 0.003s
    And the environment variable "HUGGINGFACE_API_KEY" is set to "test-key" ... passed in 0.000s
    And a fake requests library returns HuggingFace OCR response for model "PaddlePaddle/PaddleOCR-VL" with text "Env key works" ... passed in 0.000s
    And a file "image.png" exists with bytes: ... passed in 0.000s
      """
      \x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\x00\x01\x00\x00\x00\x01\x08\x02\x00\x00\x00\x90wS\xde\x00\x00\x00\x0bIDATx\x9cc\x00\x01\x00\x00\x05\x00\x01\r\n-\xb4\x00\x00\x00\x00IEND\xaeB`\x82
      """
    When I ingest the file "image.png" into corpus "corpus" ... passed in 0.004s
    And I build a "ocr-paddleocr-vl" extraction run in corpus "corpus" using the recipe: ... passed in 0.005s
      """
      extractor_id: ocr-paddleocr-vl
      config:
        backend:
          mode: api
          api_provider: huggingface
          model_id: "PaddlePaddle/PaddleOCR-VL"
      """
    Then the extracted text for the last ingested item equals "Env key works" ... passed in 0.000s

@scenario.end
--------------------------------------------------------------------------------
]]>
</system-out></testcase><testcase classname="inference_backend.Inference backend configuration" name="API mode reads HuggingFace API key from config file" status="passed" time="0.015579"><system-out>
<![CDATA[
@scenario.begin
  Scenario: API mode reads HuggingFace API key from config file
    Given I initialized a corpus at "corpus" ... passed in 0.003s
    And a local Biblicus user config exists with HuggingFace API key "config-key" ... passed in 0.000s
    And a fake requests library returns HuggingFace OCR response for model "PaddlePaddle/PaddleOCR-VL" with text "Config key works" ... passed in 0.000s
    And a file "image.png" exists with bytes: ... passed in 0.000s
      """
      \x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\x00\x01\x00\x00\x00\x01\x08\x02\x00\x00\x00\x90wS\xde\x00\x00\x00\x0bIDATx\x9cc\x00\x01\x00\x00\x05\x00\x01\r\n-\xb4\x00\x00\x00\x00IEND\xaeB`\x82
      """
    When I ingest the file "image.png" into corpus "corpus" ... passed in 0.004s
    And I build a "ocr-paddleocr-vl" extraction run in corpus "corpus" using the recipe: ... passed in 0.007s
      """
      extractor_id: ocr-paddleocr-vl
      config:
        backend:
          mode: api
          api_provider: huggingface
          model_id: "PaddlePaddle/PaddleOCR-VL"
      """
    Then the extracted text for the last ingested item equals "Config key works" ... passed in 0.000s

@scenario.end
--------------------------------------------------------------------------------
]]>
</system-out></testcase><testcase classname="inference_backend.Inference backend configuration" name="API mode accepts API key override in config" status="passed" time="0.01299"><system-out>
<![CDATA[
@scenario.begin
  Scenario: API mode accepts API key override in config
    Given I initialized a corpus at "corpus" ... passed in 0.003s
    And a fake requests library returns HuggingFace OCR response for model "PaddlePaddle/PaddleOCR-VL" with text "Override key works" ... passed in 0.000s
    And a file "image.png" exists with bytes: ... passed in 0.000s
      """
      \x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\x00\x01\x00\x00\x00\x01\x08\x02\x00\x00\x00\x90wS\xde\x00\x00\x00\x0bIDATx\x9cc\x00\x01\x00\x00\x05\x00\x01\r\n-\xb4\x00\x00\x00\x00IEND\xaeB`\x82
      """
    When I ingest the file "image.png" into corpus "corpus" ... passed in 0.004s
    And I build a "ocr-paddleocr-vl" extraction run in corpus "corpus" using the recipe: ... passed in 0.005s
      """
      extractor_id: ocr-paddleocr-vl
      config:
        backend:
          mode: api
          api_provider: huggingface
          api_key: "override-key"
          model_id: "PaddlePaddle/PaddleOCR-VL"
      """
    Then the extracted text for the last ingested item equals "Override key works" ... passed in 0.000s

@scenario.end
--------------------------------------------------------------------------------
]]>
</system-out></testcase><testcase classname="inference_backend.Inference backend configuration" name="API mode resolves OpenAI API key from environment" status="passed" time="0.003825"><system-out>
<![CDATA[
@scenario.begin
  Scenario: API mode resolves OpenAI API key from environment
    Given I initialized a corpus at "corpus" ... passed in 0.003s
    And the environment variable "OPENAI_API_KEY" is set to "test-openai-key" ... passed in 0.000s
    When I call resolve_api_key for OpenAI provider with no config override ... passed in 0.000s
    Then the resolved API key equals "test-openai-key" ... passed in 0.000s

@scenario.end
--------------------------------------------------------------------------------
]]>
</system-out></testcase><testcase classname="inference_backend.Inference backend configuration" name="API mode resolves OpenAI API key from config file" status="passed" time="0.004093"><system-out>
<![CDATA[
@scenario.begin
  Scenario: API mode resolves OpenAI API key from config file
    Given I initialized a corpus at "corpus" ... passed in 0.003s
    And a local Biblicus user config exists with OpenAI API key "config-openai-key" ... passed in 0.000s
    When I call resolve_api_key for OpenAI provider with no config override ... passed in 0.001s
    Then the resolved API key equals "config-openai-key" ... passed in 0.000s

@scenario.end
--------------------------------------------------------------------------------
]]>
</system-out></testcase><testcase classname="inference_backend.Inference backend configuration" name="API mode returns None for OpenAI when no key is configured" status="passed" time="0.003803"><system-out>
<![CDATA[
@scenario.begin
  Scenario: API mode returns None for OpenAI when no key is configured
    Given I initialized a corpus at "corpus" ... passed in 0.003s
    When I call resolve_api_key for OpenAI provider with no config override ... passed in 0.000s
    Then the resolved API key is None ... passed in 0.000s

@scenario.end
--------------------------------------------------------------------------------
]]>
</system-out></testcase><testcase classname="inference_backend.Inference backend configuration" name="API mode returns None for unknown provider" status="passed" time="0.003519"><system-out>
<![CDATA[
@scenario.begin
  Scenario: API mode returns None for unknown provider
    Given I initialized a corpus at "corpus" ... passed in 0.003s
    When I call resolve_api_key for unknown provider with no config override ... passed in 0.000s
    Then the resolved API key is None ... passed in 0.000s

@scenario.end
--------------------------------------------------------------------------------
]]>
</system-out></testcase></testsuite>